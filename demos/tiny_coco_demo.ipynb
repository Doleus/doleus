{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing an Object Detection Model with Doleus\n",
    "\n",
    "This notebook demonstrates how to use **Doleus** to test an object detection model across different data slices. We use a small subset of the COCO validation dataset (**TinyCocoDataset**, 50 images) and create slices based on:\n",
    "- Image brightness (\"brighter\" vs. \"darker\")\n",
    "- Metadata (\"indoor\" vs. \"outdoor\")\n",
    "\n",
    "We use the pre-trained **Faster R-CNN (ResNet50-FPN v2)** model from TorchVision.\n",
    "\n",
    "### Steps in this tutorial:\n",
    "1. Download the TinyCocoDataset.\n",
    "2. Create a PyTorch dataset.\n",
    "3. Slice the dataset based on brightness and metadata.\n",
    "4. Generate predictions using the model.\n",
    "5. Evaluate performance on each data slice with Doleus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import requests\n",
    "import zipfile\n",
    "\n",
    "from torchvision.datasets import CocoDetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyCocoDataset(CocoDetection):\n",
    "    \"\"\"\n",
    "    A simplified dataset class for Tiny COCO.\n",
    "    Inherits from torchvision's CocoDetection but only loads bounding boxes.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def download_dataset(dir: str = \"tiny_coco\", url: str = \"https://www.dropbox.com/scl/fo/ea21g39o29gihqqyd239w/ALuoU3X4UigKJuJVySSyXVk?rlkey=jloatvwfq3024l5701m29g2ij&st=7071uuzd&dl=1\"):\n",
    "        \"\"\"Download the demo dataset from Dropbox, store it in dir, unzip it and return the directory\"\"\"\n",
    "        if os.path.exists(dir):\n",
    "            return dir\n",
    "            \n",
    "        os.makedirs(dir, exist_ok=True)\n",
    "        \n",
    "        zip_path = f\"{dir}.zip\"\n",
    "        response = requests.get(url)\n",
    "        \n",
    "        with open(zip_path, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "                \n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(dir)\n",
    "            \n",
    "        os.remove(zip_path)\n",
    "        return dir\n",
    "    \n",
    "    def __init__(\n",
    "        self, root: str | None = None, split: str = \"val\", transform=None, target_transform=None\n",
    "    ) -> None:\n",
    "        if root is None:\n",
    "            root = TinyCocoDataset.download_dataset()\n",
    "        ann_file = os.path.join(root, \"annotations\", f\"instances_{split}2017.json\")\n",
    "        img_folder = os.path.join(root, f\"{split}2017\")\n",
    "        super().__init__(\n",
    "            img_folder, ann_file, transform=transform, target_transform=target_transform\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        img, target = super().__getitem__(idx)\n",
    "\n",
    "        if target:\n",
    "            boxes = torch.tensor([ann[\"bbox\"] for ann in target], dtype=torch.float32)\n",
    "        else:\n",
    "            boxes = torch.empty((0, 4), dtype=torch.float32)\n",
    "        boxes = box_convert(boxes, in_fmt=\"xywh\", out_fmt=\"xyxy\")\n",
    "\n",
    "        labels = [ann[\"category_id\"] for ann in target]\n",
    "        return img, boxes, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Load and Prepare the Dataset\n",
    "\n",
    "We have prepared a subset of the Coco Dataset (https://cocodataset.org/#home) for download. It is 9.1 MB in size and contains 50 images from the COCO validation set, their respective annotations and some additional metadata. \n",
    "\n",
    "**Dataset Details:**\n",
    "- The dataset consists of 50 images from the COCO validation set.\n",
    "- Each image has corresponding annotations (bounding boxes, labels).\n",
    "- Additional metadata includes location information (e.g., 'indoor' or 'outdoor')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TinyCocoDataset() #This will download the dataset and store it in the current working directory as tiny_coco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3:  Initialize the Model and Preprocess Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.detection import FasterRCNN_ResNet50_FPN_V2_Weights, fasterrcnn_resnet50_fpn_v2\n",
    "\n",
    "weights = FasterRCNN_ResNet50_FPN_V2_Weights.COCO_V1\n",
    "model = fasterrcnn_resnet50_fpn_v2(weights=weights)\n",
    "model.eval()\n",
    "\n",
    "preprocess = weights.transforms()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Create Predictions for the Dataset\n",
    "Depending on your computing infrastructure, this can take a couple of minutes for all 50 images.\n",
    "You can execute the code that processes only a subset to increase the speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.ops import box_convert\n",
    "\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for idx in range(len(dataset)):\n",
    "        img, gt_boxes, gt_labels = dataset[idx]\n",
    "\n",
    "        img_processed = preprocess(img)\n",
    "        prediction = model([img_processed])[0]\n",
    "\n",
    "        # Save predictions in the format expected by Doleus\n",
    "        pred_entry = {\n",
    "            \"boxes\": prediction[\"boxes\"].cpu(),\n",
    "            \"labels\": prediction[\"labels\"].cpu(),\n",
    "            \"scores\": prediction[\"scores\"].cpu(),\n",
    "        }\n",
    "        predictions.append(pred_entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Create a Doleus Dataset Wrapper and Add Metadata\n",
    "\n",
    "**Why Wrap the Dataset?**\n",
    "- Using `DoleusDetection`, we can associate model predictions with the images in the dataset.\n",
    "- This allows us to apply tests to different data slices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moonwatcher.dataset.dataset import MoonwatcherDetection\n",
    "\n",
    "moonwatcher_dataset = MoonwatcherDetection(\n",
    "    name=\"tiny-coco-val-subset\",\n",
    "    dataset=dataset,\n",
    "    num_classes=91,  # COCO has 91 classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associate the model predictions with the dataset\n",
    "moonwatcher_dataset.add_model_predictions(predictions, \"faster_rcnn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding pre-defined metadata\n",
    "Doleus offers some methods that add metadata out of the box. These metadates are based on classic image statistics.\n",
    "\n",
    "**Why Metadata Matters?**\n",
    "- Metadata provides additional insights beyond raw labels.\n",
    "- Using attributes like brightness, contrast, or resolution, we can analyze whether certain factors impact model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predefined metadata (\"brightness\") to allow slicing based on image properties\n",
    "moonwatcher_dataset.add_predefined_metadata(\"brightness\")\n",
    "\n",
    "# You can add other predefined metadata as well and perform slicing based on them\n",
    "# moonwatcher_dataset.add_predefined_metadata(\"contrast\")\n",
    "# moonwatcher_dataset.add_predefined_metadata(\"saturation\")\n",
    "# moonwatcher_dataset.add_predefined_metadata(\"resolution\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding custom metadata\n",
    "With Doleus you can also add custom metadata. We have prepared a metadata file that assigns each image to the location of either \"indoor\" or \"outdoor\"\n",
    "\n",
    "**Custom Metadata Example:**\n",
    "- The dataset includes a CSV file that assigns images to 'indoor' or 'outdoor' categories.\n",
    "- This allows us to evaluate if the model behaves differently in varying environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "metadata = pd.read_csv(\"tiny_coco/metadata/tiny_coco_metadata.csv\")\n",
    "\n",
    "# For the complete dataset with 50 images, the metadata file has 50 rows.\n",
    "moonwatcher_dataset.add_metadata_from_dataframe(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Slices based on metadata\n",
    "Now we create slices based on the metadata we have defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create slices based on brightness percentile\n",
    "slice_bright = moonwatcher_dataset.slice_by_percentile(\"brightness\", \">=\", 50)\n",
    "slice_dim = moonwatcher_dataset.slice_by_percentile(\"brightness\", \"<\", 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create slices based on location\n",
    "slice_indoor = moonwatcher_dataset.slice_by_metadata_value(\"location\", \"indoor\")\n",
    "slice_outdoor = moonwatcher_dataset.slice_by_metadata_value(\"location\", \"outdoor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create checks for each of the slices\n",
    "We can create Checks for each Slice to evaluate and analyze their respective performance.\n",
    "\n",
    "**What Are Checks?**\n",
    "- Checks define performance criteria (e.g., `mAP > 0.8`) for a dataset or slice and a model.\n",
    "- If a Check fails, it indicates that the slice doesn't perform as well as expected.\n",
    "- That helps you to identify subsets of the data that underperform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moonwatcher.check import Check\n",
    "\n",
    "check_map_bright = Check(\n",
    "    name=\"map_bright\",\n",
    "    dataset=slice_bright,\n",
    "    model_id=\"faster_rcnn\",\n",
    "    metric=\"mAP\",\n",
    "    operator=\">\",\n",
    "    value=0.8,\n",
    ")\n",
    "\n",
    "check_map_dim = Check(\n",
    "    name=\"map_dim\",\n",
    "    dataset=slice_dim,\n",
    "    model_id=\"faster_rcnn\",\n",
    "    metric=\"mAP\",\n",
    "    operator=\">\",\n",
    "    value=0.8,\n",
    ")\n",
    "\n",
    "check_map_indoor = Check(\n",
    "    name=\"map_indoor\",\n",
    "    dataset=slice_indoor,\n",
    "    model_id=\"faster_rcnn\",\n",
    "    metric=\"mAP\",\n",
    "    operator=\">\",\n",
    "    value=0.8,\n",
    ")\n",
    "\n",
    "check_map_outdoor = Check(\n",
    "    name=\"map_outdoor\",\n",
    "    dataset=slice_outdoor,\n",
    "    model_id=\"faster_rcnn\",\n",
    "    metric=\"mAP\",\n",
    "    operator=\">\",\n",
    "    value=0.8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining the Checks into a Checksuite\n",
    "\n",
    "**Why Use a CheckSuite?**\n",
    "- Instead of running individual checks manually, a `CheckSuite` groups multiple checks together.\n",
    "- This allows for easy evaluation across different dataset slices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moonwatcher.check import CheckSuite\n",
    "\n",
    "check_suite = CheckSuite(\n",
    "    name=\"check_suite\",\n",
    "    checks=[check_map_bright, check_map_dim, check_map_indoor, check_map_outdoor],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can run the Checksuite and save the results as a JSON file\n",
    "report = check_suite.run_all(show=True)\n",
    "report.to_json(\"check_suite_report.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moonwatcher-SQx8c_9f-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
